{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n\nimport cv2\nimport os\nimport timm\nimport torch\nimport time\nimport random\nimport sklearn\nimport warnings\nimport pydicom\nimport joblib\nimport logging\nimport pandas as pd\nimport numpy as np\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom tqdm import tqdm\nfrom datetime import datetime\nfrom glob import glob\nfrom skimage import io\nfrom scipy.ndimage.interpolation import zoom\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.nn.modules.loss import _WeightedLoss\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, log_loss\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OUTPUT_DIR = './'\nMODEL_DIR = {'vit':'../input/vit-labelsmooth-3101/vit_labelsmooth_3101',\n             'effnet':'../input/effnet-taylorsmooth-3001/effnet_taylor_smooth_3001',\n             'resnext': '../input/resnext50-symm-1502/resnext50_32x4d_1502',\n             'resnet': '../input/resnet200d-1602/resnet300d_1502',\n             'nfnet': '../input/nfnet-1702/nf_resnet50_1702'}\n\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\nTRAIN_PATH = '../input/cassava-leaf-disease-classification/train_images'\nTEST_PATH = '../input/cassava-leaf-disease-classification/test_images'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CFG:\n    debug=False\n    num_workers=4\n    model_zoo = ['effnet','vit','nfnet','resnet','resnext']\n    model = None\n    model_name= {'vit':'vit_base_patch16_384',\n                 'effnet':'tf_efficientnet_b4_ns',\n                 'resnext': 'resnext50_32x4d',\n                 'resnet': 'resnet200d',\n                 'nfnet': 'nf_resnet50'}\n    \n    size={'vit':384,\n          'effnet':512,\n          'resnext': 512,\n          'resnet': 512,\n          'nfnet': 512}\n    \n    batch_size=32\n    seed=2020\n    num_class=5\n    target_col='label'\n    fold=1\n    num_fold=[1,2,3,4,5]\n    pretrained=False\n    tta=4\n    used_epochs=[6,7,8,9]\n    weights=[1,1,1,1]\n    \n    #validation\n    num_folds = 5\n    image_col_name = 'image_id'\n    class_col_name = 'label'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def seed_torch(seed=2020):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_torch(seed=CFG.seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\nvalid = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ValidDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['image_id'].values\n        self.labels = df['label'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        file_name = self.file_names[idx]\n        file_path = os.path.join(TRAIN_PATH, file_name)\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image\n\n\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['image_id'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{TEST_PATH}/{file_name}'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_transforms(*, data):\n    \n    if data == 'train':\n        return Compose([\n            #Resize(CFG.size, CFG.size),\n            RandomResizedCrop(CFG.size[CFG.model], CFG.size[CFG.model]),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return Compose([\n            RandomResizedCrop(CFG.size[CFG.model], CFG.size[CFG.model]),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            Transpose(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Effnet(nn.Module):\n    \"\"\"\n    EfficientNet model by https://arxiv.org/pdf/1905.11946.pdf\n    \"\"\"\n    def __init__(self, model_name, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n\nclass ViT(nn.Module):\n    \"\"\"\n    VisionTransformer model by https://arxiv.org/pdf/2010.11929.pdf\n    \"\"\"\n    def __init__(self, model_name, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        self.model.head = nn.Linear(self.model.head.in_features, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n    \n    \nclass Resnext(nn.Module):\n    def __init__(self, model_name, n_class, pretrained=False):\n          super().__init__()\n          self.model = timm.create_model(model_name, pretrained=pretrained)\n          n_features = self.model.fc.in_features\n          self.model.fc = nn.Linear(n_features, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n    \n    \nclass Resnet(nn.Module):\n    def __init__(self, model_name, n_class, pretrained=False):\n          super().__init__()\n          self.model = timm.create_model(model_name, pretrained=pretrained)\n          n_features = self.model.fc.in_features\n          self.model.fc = nn.Linear(n_features, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n\nclass NFNet(nn.Module):\n    def __init__(self, model_name, n_class, pretrained=False):\n          super().__init__()\n          self.model = timm.create_model(model_name, pretrained=pretrained)\n          n_features = self.model.head.fc.in_features\n          self.model.head.fc = nn.Linear(n_features, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n\ndef create_model(config):\n    if config.model == \"effnet\":\n        model_obj = Effnet\n        model = Effnet(config.model_name[config.model], config.num_class, config.pretrained)\n        return model\n\n    if config.model == 'vit':\n        model_obj = ViT\n        model = ViT(config.model_name[config.model], config.num_class, config.pretrained)\n        return model\n    \n    if config.model == 'resnext':\n        model_obj = Resnext\n        model = Resnext(config.model_name[config.model], config.num_class, config.pretrained)\n        return model\n\n    if config.model == 'resnet':\n        model_obj = Resnet\n        model = Resnet(config.model_name[config.model], config.num_class, config.pretrained)\n        return model\n    \n    if config.model == 'nfnet':\n        model_obj = NFNet\n        model = NFNet(config.model_name[config.model], config.num_class, config.pretrained)\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference(model, states, test_loader, device):\n    model.to(device)\n    model.load_state_dict(states['model_state_dict'])\n    model.eval()\n    tbar = tqdm(enumerate(test_loader), total=len(test_loader))\n    full_pred = []\n    batch_pred = []\n    for i, (images) in tbar:\n        images = images.to(device)\n        with torch.no_grad():\n            y_preds = model(images)\n        batch_pred+=[y_preds.softmax(1).to('cpu').numpy()]\n    full_pred = np.concatenate(batch_pred)\n    return full_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_validation_fold(num_folds, val_df):\n    skf = StratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=CFG.seed).split(\n                        X=val_df[CFG.image_col_name], y=val_df[CFG.class_col_name])\n    \n    for fold, (train_idx, val_idx) in enumerate(skf):\n        val_df.loc[val_idx, 'fold'] = int(fold+1)\n    \n    return val_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def blend():\n    models_oof = []\n    for net in CFG.model_zoo:\n        CFG.model = net\n        print(CFG.model)\n        model = create_model(CFG)\n        oof_pred = []\n        for folds in (i+1 for i in range(CFG.num_folds)):\n            checkpoint_path = os.path.join(MODEL_DIR[CFG.model],f'{CFG.model_name[CFG.model]}_fold{folds}.pt')\n            print('Loading {} checkpoint oof'.format(checkpoint_path))\n            states = torch.load(checkpoint_path)\n            oof_pred += [states['oof_preds']]\n        oof_pred = np.concatenate(oof_pred)\n        models_oof += [oof_pred]\n    \n    return models_oof\n    \n    \n\ndef validate_on_fold(fold, df):\n    valid_df = df[df[\"fold\"] == fold].reset_index(drop=True)\n    valid_dataset = ValidDataset(valid_df, transform=get_transforms(data='valid'))\n    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True)\n    checkpoint_path = os.path.join(MODEL_DIR[CFG.model],f'{CFG.model_name[CFG.model]}_fold{folds}.pt')\n    print('Loading {} checkpoint'.format(checkpoint_path))\n    states = torch.load(checkpoint_path)\n    \n    tta_stack = []\n    for _ in range(CFG.tta):\n        tta_stack += [inference(model, states, valid_loader, device)/CFG.tta]\n        \n    tta_stack = np.mean(tta_stack, axis=0)\n    valid_df['pred'] = tta_stack.argmax(1)\n    return valid_df, tta_stack","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = blend()\nvalidate_df = pd.DataFrame()\nvalid_fold = make_validation_fold(CFG.num_folds, valid)\nfor folds in (number+1 for number in range(CFG.num_folds)):\n    valid_ = valid_fold[valid_fold[\"fold\"] == folds].reset_index(drop=True)\n    validate_df = pd.concat([validate_df, valid_], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # ### Validation\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# final_ensemble = []\n# valid = make_validation_fold(CFG.num_folds, valid)\n\n# for net in CFG.model_zoo[2:]:\n#     fold_stack = []\n#     validate_df = pd.DataFrame()\n#     CFG.model = net\n#     model = create_model(CFG)\n    \n#     print('Validating {}'.format(CFG.model))\n#     for folds in (number+1 for number in range(CFG.num_folds)):\n#         fold_df, tta_stack = validate_on_fold(folds, valid)\n#         validate_df = pd.concat([validate_df,fold_df])\n#         fold_stack += [tta_stack]\n#         print(\"Fold {} TTA: {}\".format(folds, metrics.accuracy_score(y_true=fold_df['label'], y_pred=fold_df['pred'])))\n        \n#     print(metrics.accuracy_score(y_true=validate_df['label'], y_pred=validate_df['pred']))\n#     model_stack = np.concatenate(fold_stack, axis=0)\n#     final_ensemble += [model_stack]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Inference\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nfinal_ensemble = []\n\n\n#valid = make_validation_fold(CFG.num_folds, valid)\nfor net in CFG.model_zoo:\n    CFG.model = net\n    model = create_model(CFG)\n    model_ensemble = []\n    \n    print('Evaluating {}'.format(CFG.model))\n     \n    test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                             num_workers=CFG.num_workers, pin_memory=True)\n       \n    print('Inference...')\n    for folds in CFG.num_fold:\n        checkpoint_path = os.path.join(MODEL_DIR[CFG.model],f'{CFG.model_name[CFG.model]}_fold{folds}.pt')\n        print('Loading {} checkpoint'.format(checkpoint_path))\n        states = torch.load(checkpoint_path)\n\n        for _ in range(CFG.tta):\n            model_ensemble += [inference(model, states, test_loader, device)/CFG.tta]\n\n    model_ensemble = np.mean(model_ensemble, axis=0)\n    final_ensemble += [model_ensemble]\n# print(final_ensemble)\nfinal_ensemble = np.mean(final_ensemble, axis=0)\n# final_ensemble = (0.25*final_ensemble[0]) + (0.2*final_ensemble[1]) + (0.25*final_ensemble[2]) + (0.25*final_ensemble[3]) + (0.05*final_ensemble[4])\n\n\n# submission\ntest['label'] = final_ensemble.argmax(1)\ntest[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}